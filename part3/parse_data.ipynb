{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "# from PIL import Image\n",
    "import xml.etree.ElementTree as ET\n",
    "# from io import BytesIO\n",
    "# import dlib\n",
    "# from xmltodict import parse\n",
    "import _pickle as pickle\n",
    "import sys\n",
    "from csv import reader\n",
    "from xml.dom import minidom\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data3 = \"data/data3/\"\n",
    "path_im3=\"data/data3/images/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_data3+'train.csv')\n",
    "data3_df = df[(df['classname'] == 'face_with_mask') | (df['classname'] == 'face_no_mask')]\n",
    "data_3_group_by_name = data3_df.groupby(\"name\")\n",
    "\n",
    "# image3_df = data3_df.apply(lambda row: cv2.cvtColor(cv2.imread(os.path.join(path_im3,row['name'])),cv2.COLOR_BGR2RGB), axis=1)\n",
    "\n",
    "# data3_df = data3_df.merge(image3_df.rename('image'), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data1 = \"data/data1/\"\n",
    "path_im1_with=\"data/data1/with_mask/\"\n",
    "path_im1_without=\"data/data1/without_mask/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBoundaryBoxPoints(img, objectList, net, label=None):\n",
    "    h, w = img.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(img, 1.0,(300, 300), (104.0, 117.0, 123.0))\n",
    "    net.setInput(blob)\n",
    "    faces = net.forward()\n",
    "    #to draw faces on image\n",
    "    rectangle_list = []\n",
    "    for i in range(faces.shape[2]):\n",
    "            objectDict = {}\n",
    "            confidence = faces[0, 0, i, 2]\n",
    "            if confidence > 0.76:\n",
    "                box = faces[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                (x, y, x1, y1) = box.astype(\"int\")\n",
    "                (startX, startY) = (max(0, x), max(0, y))\n",
    "                (endX, endY) = (min(w - 1, x1), min(h - 1, y1))\n",
    "                \n",
    "                objectDict['name'] = filename.rsplit('/', 1)[-1]\n",
    "                objectDict['classname'] = label\n",
    "                objectDict['x1'] = startX\n",
    "                objectDict['y1'] = startY\n",
    "                objectDict['x2'] = endX\n",
    "                objectDict['y2'] = endY\n",
    "#                 objectDict['image'] = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "                objectList.append(dict(objectDict))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: change code later \n",
    "modelFile = \"models/res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "configFile = \"models/deploy.prototxt\"\n",
    "net = cv2.dnn.readNetFromCaffe(path_data1+configFile, path_data1+modelFile)\n",
    "objectList_with = []\n",
    "objectList_without = []\n",
    "\n",
    "for filename in os.listdir(path_im1_with):\n",
    "    img = cv2.imread(path_im1_with+filename)\n",
    "    if img is not None:\n",
    "        getBoundaryBoxPoints(img, objectList_with, net, 'face_with_mask')\n",
    "    \n",
    "for filename in os.listdir(path_im1_without):\n",
    "    img = cv2.imread(path_im1_without+filename)\n",
    "    if img is not None:\n",
    "        getBoundaryBoxPoints(img, objectList_without, net, 'face_no_mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_df_with = pd.DataFrame.from_records(objectList_with)\n",
    "data_1_with_group_by_name = data1_df_with.groupby(\"name\")\n",
    "# data1_df.to_csv('data1.csv')\n",
    "\n",
    "data1_df_without = pd.DataFrame.from_records(objectList_without)\n",
    "data_1_without_group_by_name = data1_df_without.groupby(\"name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size(path,name):\n",
    "    image = cv2.cvtColor(cv2.imread(os.path.join(path+'images/',name)),cv2.COLOR_BGR2RGB)\n",
    "    return image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_max(num1,num2):\n",
    "    if num1 <= num2:\n",
    "        return num1,num2\n",
    "    else:\n",
    "        return num2,num1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_xml(file_path,imagename,group):\n",
    "    annotation = ET.Element(\"annotation\") \n",
    "    \n",
    "    folder = ET.SubElement(annotation, \"folder\") \n",
    "    folder.text = \"images\"\n",
    "    filename = ET.SubElement(annotation, \"filename\") \n",
    "    filename.text = imagename\n",
    "    size = ET.SubElement(annotation, \"size\") \n",
    "    \n",
    "    imagelength,imagewidth,imagechannel = get_size(file_path,imagename)\n",
    "    width = ET.SubElement(size,\"width\")\n",
    "    width.text = str(imagewidth)\n",
    "    length = ET.SubElement(size,\"length\")\n",
    "    length.text = str(imagelength)\n",
    "    depth = ET.SubElement(size,\"depth\")\n",
    "    depth.text = str(imagechannel)\n",
    "    \n",
    "    segmented = ET.SubElement(annotation,\"segmented\")\n",
    "    segmented.text = '0'\n",
    "        \n",
    "    for i,row in group.iterrows():\n",
    "        obj = ET.SubElement(annotation,\"object\")\n",
    "        name = ET.SubElement(obj,\"name\")\n",
    "        name.text = row['classname']\n",
    "        pose = ET.SubElement(obj,\"pose\")\n",
    "        pose.text = \"none\"\n",
    "        truncated = ET.SubElement(obj,\"truncated\")\n",
    "        truncated.text = \"0\"\n",
    "        occluded = ET.SubElement(obj,\"occluded\")\n",
    "        occluded.text = \"0\"\n",
    "        difficult = ET.SubElement(obj,\"difficult\")\n",
    "        difficult.text = \"0\"\n",
    "        bndbox = ET.SubElement(obj,\"bndbox\")\n",
    "        \n",
    "        imagexmin,imagexmax = get_min_max(row['x1'],row['x2'])\n",
    "        imageymin,imageymax = get_min_max(row['y1'],row['y2'])\n",
    "        \n",
    "        \n",
    "        xmin = ET.SubElement(bndbox,\"xmin\")\n",
    "        xmin.text = str(imagexmin)\n",
    "        ymin = ET.SubElement(bndbox,\"ymin\")\n",
    "        ymin.text = str(imageymin)\n",
    "        xmax = ET.SubElement(bndbox,\"xmax\")\n",
    "        xmax.text = str(imagexmax)\n",
    "        ymax = ET.SubElement(bndbox,\"ymax\")\n",
    "        ymax.text = str(imageymax)\n",
    "        \n",
    "        voc = ET.ElementTree(annotation) \n",
    "              \n",
    "    with open(file_path+'voc/'+imagename[:-4]+\".xml\", \"wb\") as f : \n",
    "        voc.write(f) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group in data_1_with_group_by_name:\n",
    "    create_xml(path_im1_with,name,group)     \n",
    "for name, group in data_1_without_group_by_name:\n",
    "    create_xml(path_im1_without,name,group) \n",
    "for name, group in data_3_group_by_name:\n",
    "    create_xml(path_data3,name,group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_im2=\"data/data2/images/\" \n",
    "path_xml2=\"data/data2/annotations/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getObjectProperties(filename, objectList):\n",
    "    objectDict = {}\n",
    "    for event_type, element in  ET.iterparse(filename, events=('start', 'end')):\n",
    "        if event_type == 'start' and element.tag == 'filename':\n",
    "            objectDict['name'] = element.text\n",
    "        if event_type == 'end' and element.tag == 'name':\n",
    "            objectDict['classname'] = element.text\n",
    "        if event_type == 'end' and element.tag == 'xmin':\n",
    "            objectDict['x1'] = int(element.text)\n",
    "        if event_type == 'end' and element.tag == 'ymin':\n",
    "            objectDict['y1'] = int(element.text)\n",
    "        if event_type == 'end' and element.tag == 'xmax':\n",
    "            objectDict['x2'] = int(element.text)\n",
    "        if event_type == 'end' and element.tag == 'ymax':\n",
    "            objectDict['y2'] = int(element.text)\n",
    "        if event_type == 'end' and element.tag == 'object':\n",
    "            objectList.append(dict(objectDict))\n",
    "    return objectList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "objectList = []\n",
    "for filename in os.listdir(path_xml2):\n",
    "    with open(path_xml2+filename) as fd:\n",
    "        getObjectProperties(fd,objectList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data2.csv\n",
      "Done\n",
      "Generating data2.pkl\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "data2_df = pd.DataFrame.from_records(objectList)\n",
    "image2_df = data2_df.apply(lambda row: cv2.cvtColor(cv2.imread(os.path.join(path_im2,row['name'])),cv2.COLOR_BGR2RGB), axis=1)\n",
    "data2_df = data2_df.merge(image2_df.rename('image'), left_index=True, right_index=True)\n",
    "\n",
    "data2_df['classname'] = data2_df['classname'].replace(['with_mask','without_mask'],['face_with_mask','face_no_mask'])\n",
    "print(\"Generating data2.csv\")\n",
    "data2_df.to_csv('data2.csv')\n",
    "print(\"Done\")\n",
    "\n",
    "print(\"Generating data2.pkl\")\n",
    "with open(\"data2.pkl\", 'wb') as output:\n",
    "    pickle.dump(data2_df, output, -1)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all csv\n",
    "data1 = pd.read_csv(\"data1.csv\",header=0)\n",
    "data2 = pd.read_csv(\"data2.csv\",header=0)\n",
    "data3 = pd.read_csv(\"data3.csv\",header=0)\n",
    "merged_data = pd.concat([data1,data2,data3],ignore_index=True,sort=False)\n",
    "merged_data.to_csv('all_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
